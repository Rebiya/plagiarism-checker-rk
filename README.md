
# ğŸ“š Plagiarism Detector + Autocomplete System

### (Trie + Rabinâ€“Karp + WordNet Synonym Awareness)

An end-to-end system that combines **synonym-aware plagiarism detection** with a **high-performance Trie autocomplete engine**.
Supports **PDF/text uploads**, cleaning, hashing, plagiarism scoring, semantic matching, and autocomplete suggestions inside a **Streamlit UI**.

ğŸ“Œ [Sequence Diagram](https://drive.google.com/file/d/1lka8H2hE3M1fsx4-Pqvljg8ZQ1s4lh04/view?usp=sharing)

ğŸ“Œ [Use-Case Diagram](https://drive.google.com/file/d/1mIpJhoXA_cmK9TAabGXjbyIushrg9zDT/view?usp=sharing)

---

## âœ¨ Key Features

### ğŸ” Plagiarism Detection

* Rabinâ€“Karp hashing for substring similarity.
* **Semantic plagiarism detection via WordNet synonyms**.
* Accepts both **text input** and **PDF uploads** (Streamlit).
* Normalize & clean text for consistent matching.
* Download plagiarism result as CSV.
* **Reference hashing & vocabulary lookup**.
* CLI and Streamlit UI.

### âš¡ Trie Auto-Completion

* Prefix lookup in **O(k)** time (k = prefix length).
* Built offline â†’ loaded at runtime.
* Streamlit **live suggestions** using callback.

### ğŸ¯ Streamlit UI

* Upload documents.
* Compute plagiarism score.
* Live autocomplete suggestions.
* Replace last typed token when a suggestion is selected.

---

# ğŸ§  System Architecture

```
User (Streamlit UI)
   â”œâ”€ Text Input (typing)
   â”œâ”€ File Upload (.txt / .pdf)
   â†“
Backend Pipeline
 â”œâ”€ Text Processing
 â”‚   â”œâ”€ Cleaning / Normalization
 â”‚   â””â”€ Tokenization
 â”œâ”€ Plagiarism Module (Rabinâ€“Karp)
 â”‚   â”œâ”€ Load Reference Hashes
 â”‚   â”œâ”€ Compute Suspect Hashes
 â”‚   â”œâ”€ Compare Matches
 â”‚   â””â”€ Score & Report
 â””â”€ Autocomplete Module (Trie)
     â”œâ”€ Load Prebuilt Trie
     â”œâ”€ Query Prefix
     â””â”€ Return Suggestions
```

---

# ğŸ“ Folder Structure

```
plagiarism-checker-rk/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ app.py                     # Main Streamlit UI entry
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ trie/
â”‚   â”‚   â””â”€â”€ trie.pkl           # Serialized Trie
â”‚   â”œâ”€â”€ hashed/
â”‚   â”‚   â”œâ”€â”€ reference_hashes.pkl
â”‚   â”‚   â””â”€â”€ vocab.pkl
â”‚   â”œâ”€â”€ cleaned_data/
â”‚   â”‚   â””â”€â”€ all_cleaned.txt
â”‚   â””â”€â”€ AUTHORS/               # Raw reference dataset
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ cli.py                 # CLI interface
â”‚   â”œâ”€â”€ hashing.py             # Rabinâ€“Karp implementation
â”‚   â”œâ”€â”€ plagiarism.py          # Core scoring + pipeline
â”‚   â”œâ”€â”€ text_processing.py     # PDF/Text cleaning
â”‚   â”œâ”€â”€ pipeline.py            # Suspect analysis orchestrator
â”‚   â”œâ”€â”€ ref_builder.py         # Build reference corpus
â”‚   â”œâ”€â”€ semantic_hashing.py    # WordNet synonym mapping
â”‚   â”œâ”€â”€ tokenizer.py           # Token utilities
â”‚   â”œâ”€â”€ trie_builder.py        # Build Trie from reference data
â”‚   â”œâ”€â”€ trie_runtime.py        # Trie loader + suggest_words()
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ web/
â”‚   â””â”€â”€ app.py                 # Streamlit app interface
â”‚
â””â”€â”€ test/                      # pytest tests
```

---

# ğŸ§© Code Interaction Overview

### 1ï¸âƒ£ Text Ingestion

* User uploads file (PDF / TXT) or types text.
* `process_uploaded_data()` extracts raw content.

### 2ï¸âƒ£ Normalization & Cleaning

Defined in `text_processing.py`:

* Lowercase
* Remove punctuation
* Condense whitespace
* Extract text from PDF
* Tokenize

### 3ï¸âƒ£ Plagiarism Detection

Rabinâ€“Karp over n-grams:

* Compute rolling hashes
* Compare against reference hash set
* Calculate similarity score (% matched)
* Return matches + metadata

### 4ï¸âƒ£ WordNet Synonym Awareness

In `semantic_hashing.py`:

* Expand tokens using WordNet synonym sets
* Hash synonym variants â†’ detect semantic match

---

# ğŸ§  Synonym-Aware Matching Example

Input:

```
student writes code
```

WordNet expansion:

```
student â†’ learner, pupil
code â†’ program, cipher
```

Thus the system detects:

* *student writes program*
* *learner writes code*
* etc.

This improves real plagiarism detection, not just string matching.

---

# ğŸŒ² Trie Autocomplete System

### Why Trie?

* Predictive suggestions in **O(k)** lookup.
* Memory-efficient prefix tree.
* No regex search or substring scan.

### Build Phase

Run:

```
python -m backend.trie_builder
```

Steps:

1. Load reference corpus
2. Tokenize
3. Insert into Trie
4. Serialize to `data/trie/trie.pkl`

### Runtime Phase

`trie_runtime.py`:

```python
trie = load_trie(TRIE_PATH)
suggest_words(prefix, limit=10)
```

Provides dynamic autocomplete suggestions in the Streamlit UI.

---

# ğŸ’» Streamlit Interface

User Interactions:

* Upload PDF/text
* Live autocomplete suggestions
* Press â€œCheck Plagiarismâ€
* View overall score + match positions

Mechanics:

* On text input â†’ send prefix to Trie
* On selection â†’ inject suggestion into input
* Plagiarism pipeline runs on submit

---

# ğŸ§ª Testing

Uses `pytest`:

* Trie search / insertion
* PDF extraction
* Synonym detection
* Token cleaning

Run:

```
pytest -v
```

---

# ğŸ§° Tech Stack

| Component      | Technology     |
| -------------- | -------------- |
| UI             | Streamlit      |
| NLP            | NLTK WordNet   |
| Data Structure | Trie           |
| Algorithm      | Rabinâ€“Karp     |
| PDF Processing | pypdf          |
| Testing        | pytest         |
| CI/CD          | GitHub Actions |

---

# â˜ï¸ Continuous Integration

* Trigger on push / pull request
* Install deps
* Run all tests
* Fail if any test breaks

---

# ğŸ”¨ Local Setup

### 1. Clone the repo

```
git clone https://github.com/username/plagiarism-checker-rk
cd plagiarism-checker-rk
```

### 2. Install dependencies

```
pip install -r requirements.txt
```

### 3. Build Reference Dataset

```
python backend/text_processing.py
```

### 4. Build Reference Hash Index

```
python -m backend.ref_builder
```

### 5. Build Trie

```
python -m backend.trie_builder
```

### 6. Launch Streamlit UI

```
streamlit run web/app.py
```

---

# ğŸ§­ CLI Usage (Optional)

Autocomplete:

```
python -m backend.cli "stud"
>>> ["student", "study", "studio"]
```

---

